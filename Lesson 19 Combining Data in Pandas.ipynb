{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SA433 &#x25aa; Data Wrangling and Visualization &#x25aa; Fall 2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 19. Combining Data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data analysis rarely involves only a single data table or DataFrame\n",
    "\n",
    "\n",
    "- Typically, we have many data tables, and we must combine them to answer the questions we're interested in\n",
    "\n",
    "\n",
    "- In this lesson, we'll learn about two fundamental ways of combining data: *concatenation* and *merging*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bunch of small example datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's start by importing Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll use the following datasets throughout this lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/df1.csv')\n",
    "df2 = pd.read_csv('data/df2.csv')\n",
    "df3 = pd.read_csv('data/df3.csv')\n",
    "\n",
    "left1 = pd.read_csv('data/left1.csv')\n",
    "right1 = pd.read_csv('data/right1.csv')\n",
    "\n",
    "left2 = pd.read_csv('data/left2.csv')\n",
    "right2 = pd.read_csv('data/right2.csv')\n",
    "\n",
    "left3 = pd.read_csv('data/left3.csv')\n",
    "right3 = pd.read_csv('data/right3.csv')\n",
    "\n",
    "left4 = pd.read_csv('data/left4.csv')\n",
    "right4 = pd.read_csv('data/right4.csv')\n",
    "\n",
    "left5 = pd.read_csv('data/left5.csv')\n",
    "right5 = pd.read_csv('data/right5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The cell below defines a function `display_side_by_side()` that allows us to display DataFrames side-by-side in a Jupyter notebook\n",
    "    - This will let us visually examine what's going on throughout this lesson a bit more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "def display_side_by_side(*dfs):\n",
    "    \"\"\"\n",
    "    Display DataFrames side-by-side\n",
    "    \"\"\"\n",
    "    html_str = ''.join([df.to_html() for df in dfs])\n",
    "    display_html(\n",
    "        html_str.replace(\n",
    "            'table', \n",
    "            'table style=\"display:inline;margin-right:20px\"'\n",
    "        ), \n",
    "        raw=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Suppose we have data in which the rows/observations are spread across multiple DataFrames\n",
    "\n",
    "\n",
    "- We can combine these DataFrames using `pd.concat()`\n",
    "\n",
    "\n",
    "- In its most basic form, `pd.concat()` takes a list of DataFrames as input, and returns a single DataFrame that combines the rows of the input DataFrames\n",
    "\n",
    "\n",
    "- For example, let's take a look at DataFrames `df1` and `df2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_side_by_side(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can combine the rows of `df1` and `df2` into a single DataFrame like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that without `.reset_index()`, each row no longer has a unique index, which might be undesirable\n",
    "\n",
    "\n",
    "- We can even concatenate DataFrames whose columns don't perfectly match\n",
    "\n",
    "\n",
    "- For example, consider `df3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_side_by_side(df1, df2, df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas will intelligently combine `df3` with `df1` and `df2` by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pd.concat()` can be used to combine DataFrames in many other ways\n",
    "\n",
    "\n",
    "- [Here's the documentation for `pd.concat()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another way to combine two DataFrames is to match rows based on the values of a **key** column common to both DataFrames\n",
    "\n",
    "\n",
    "- This is called **merging** or **joining**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Pandas, we can use the `.merge()` DataFrame method to accomplish these tasks:\n",
    "\n",
    "    ```python\n",
    "    left.merge(right, on=KEYS, how=MERGE_METHOD)\n",
    "     \n",
    "    ``` \n",
    "    \n",
    "    - `left` and `right` are the DataFrames we want to merge\n",
    "    \n",
    "    - `KEYS` is a column name or a *list* of column names we want to use to match rows from `left` and `right`\n",
    "    \n",
    "    - `MERGE_METHOD` specifies the **merge method**: `'left'`, `'right'`, `'outer'`, or `'inner'`\n",
    "        - We'll go over these soon\n",
    "        - By default, `how='inner'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Here is the documentation for `.merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)\n",
    "\n",
    "\n",
    "- To illustrate, let's consider the DataFrames `left1` and `right1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_side_by_side(left1, right1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can join the columns of `right1` with those of `left1`, matching rows by the value of `key`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By default, the merge method is `'inner'`: the rows corresponding to the *intersection* of the keys from both DataFrames are included in the resulting DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary of merge methods for the `how=...` keyword argument:\n",
    "\n",
    "| Merge method | Description |\n",
    "| :- | :- |\n",
    "| `left` | Use keys from left DataFrame only |\n",
    "| `right` | Use keys from right DataFrame only |\n",
    "| `outer` | Use union of keys from both DataFrames |\n",
    "| `inner` | Use intersection of keys from both DataFrames |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If a key does not appear in either left or right table, the value in the merged table will be `NA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Exercise 1.** Before running the code below, what does the resulting DataFrame look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "left1.merge(right1, on='key', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Exercise 2.** Before running the code below, what does the resulting DataFrame look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "left1.merge(right1, on='key', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Exercise 3.** Before running the code below, what does the resulting DataFrame look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "left1.merge(right1, on='key', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As mentioned above, the `on=...` keyword argument of `.merge()` can take a *list* of column names\n",
    "\n",
    "\n",
    "- For example, consider the DataFrames `left2` and `right2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_side_by_side(left2, right2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can merge `left2` and `right2` on the *combination* of `key1` and `key2` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-to-one, one-to-many, many-to-many joins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So far, we've only seen examples of **one-to-one joins**: the keys in both the left and right DataFrames are unique\n",
    "\n",
    "\n",
    "- In a **one-to-many join**, the keys in one DataFrame are unique, while the keys in the other DataFrame are possibly duplicated\n",
    "\n",
    "\n",
    "- For example, let's consider `left3` and `right3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_side_by_side(left3, right3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we merge `left3` and `right3` on `key`, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that the rows in `right3` are now repeated in the merged DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In a **many-to-many join**, the keys in both the left and right DataFrames are possibly duplicated\n",
    "\n",
    "\n",
    "- For example, let's consider `left4` and `right4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_side_by_side(left4, right4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we merge `left4` and `right4` on `key`, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a close look at the rows with `key` equal to `K0`\n",
    "\n",
    "\n",
    "- In the merged data set, we get *all* possible combinations of the rows from `left4` and `right4` with key equal to `K0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes we want to merge two DataFrames that have common column names (other than the key)\n",
    "\n",
    "\n",
    "- For example, let's take a look at `left5` and `right5`, which both have a column named `A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_side_by_side(left5, right5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What happens when we merge `left5` and `right5` on `key`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas handles the conflict in column names by appending `_x` to the left column names, and `_y` to the right column names\n",
    "\n",
    "\n",
    "- You can customize this behavior with the `suffixes=(LEFT_SUFFIX, RIGHT_SUFFIX)` keyword argument in `.merge()`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also use `.rename()` to clean up the column names afterwards in whatever way you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different keys for the left and right DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also specify different column names as keys for the left and right DataFrames, with the `left_on=...` and `right_on=...` keyword arguments of `.merge()`\n",
    "\n",
    "\n",
    "- For example, let's consider `left2` and `right2` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_side_by_side(left2, right2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can merge `left2` and `right2`, using `key1` as the key for `left2`, and `key2` as the key for `right2`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same folder as this notebook, there are 5 CSV files that together, give a comprehensive picture of the outbound flights from NYC airports in 2013:\n",
    "\n",
    "| Suggested DataFrame name | File | Description |\n",
    "| :- | :- | :- |\n",
    "| `flights` | `data/nycflights13_flights.csv` | Information about each flight &mdash; this is the same dataset we've worked with in previous lessons |\n",
    "| `airlines` | `data/nycflights13_airlines.csv` | Full carrier names and their corresponding abbreviated codes |\n",
    "| `airports` | `data/nycflights13_airports.csv` | Information about each airport, identified by the `faa` airport code |\n",
    "| `planes` | `data/nycflights13_planes.csv` | Information about each plane, identified by its `tailnum` |\n",
    "| `weather` | `data/nycflights13_weather.csv` | Weather information at each NYC airport for each hour |\n",
    "\n",
    "\n",
    "You'll use these datasets in the problems below. \n",
    "\n",
    "In addition, you'll also use Altair to create some visualizations based on these datasets, so import Altair, and enable the VegaFusion data transformer, since these datasets are large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.data_transformers.enable('vegafusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the 5 CSV files into DataFrames, using the suggested names above. Inspect them to get a sense of their contents. Note that:\n",
    "\n",
    "- `flights` connects to `planes` through the variable `tailnum`\n",
    "- `flights` connects to `airlines` through the variable `carrier`\n",
    "- `flights` connects to `airports` in two ways: the variables `origin` and `dest`\n",
    "- `flights` connects to `weather` through the variables `origin`, `year`, `month`, `day`, and `hour`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the DataFrame `flights` and `airlines` to create a new DataFrame with the same rows as `flights`, and includes the carrier's name (`name` in `airlines`) in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `precip` in `weather` contains the precipitation in inches, for each `origin` airport, `year`, `month`, `day`, and `hour`.\n",
    "\n",
    "Create a new DataFrame as follows. In `flights`, create a new variable containing the scheduled departure hour for each flight. Merge the DataFrames `flights` and `weather` to create a new DataFrame with the same rows as `flights`, and includes the amount of precipitation at the origin airport and the scheduled departure hour for each flight. Filter the rows in your resulting DataFrame for flights in December 2013. Drop and rename columns as necessary. \n",
    "\n",
    "Use Altair with the resulting DataFrame to create a scatter plot showing the relationship between the precipitation and departure delay among flights departing NYC airports in December 2013. Do you see what you expected?\n",
    "\n",
    "*Hint.* You may find [this list of NumPy mathematical functions](https://numpy.org/doc/stable/reference/routines.math.html) useful when computing the scheduled departure hour of each flight. Also see Lesson 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `year` in `planes` contains the year of manufacture for each plane.\n",
    "\n",
    "Create a new DataFrame as follows. Merge the DataFrames `flights` and `planes` to create a new DataFrame with the same rows as `flights`, and includes the plane's year of manufacture in each row. Drop and rename columns as necessary. Then group the flights by the plane's year of manufacture and compute the average arrival delay for each group. You should end up with a DataFrame with 2 columns: the year of manufacture, and the corresponding average arrival delay.\n",
    "\n",
    "Use Altair with the resulting DataFrame to create a line plot showing the relationship between the age of a plane and its delays among flights departing NYC airports in 2013. Do you see what you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the DataFrame `flights`, compute the number of flights from NYC airports to each destination in 2013. Merge the resulting DataFrame with `airports` so that it includes the latitude and longitude coordinates for each destination.\n",
    "\n",
    "Use Altair with the resulting DataFrame to produce a map of the United States, representing each destination with a circle whose size is proportional to the number of flights flown there from NYC airports in 2013. In the same folder as this notebook, `data/counties_10m.json` is a TopoJSON file that contains the layers `counties`, `states`, and `nation` for the United States, based on the US Census Bureau's cartographic data. Don't forget to import GeoPandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html):\n",
    "    - [Merge, join, concatenate, and compare](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lesson and problems inspired by Chapter 13 of [R for Data Science](https://r4ds.had.co.nz/)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
